{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UPSD1/NLP/blob/main/LLM%20docstring%20to%20unittest/src\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr7B8ptRPfXJ"
      },
      "source": [
        "#First trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mBhvVQs72tTN"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv~=1.0.1 lamini==3.1.0 datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBoxUrJU2s5O"
      },
      "outputs": [],
      "source": [
        "import lamini #used to pull our LLm for finetuning\n",
        "import logging #used for logging our flows\n",
        "from datetime import datetime\n",
        "from pprint import pprint #for pretty printing\n",
        "from typing import AsyncIterator, Iterator, Union #used for static casting\n",
        "from tqdm import tqdm #used to show loop progress\n",
        "import pandas as pd #used for data manipulations\n",
        "import jsonlines #used for dataset formatting\n",
        "\n",
        "from lamini.generation.generation_node import GenerationNode #used for the finetuning\n",
        "from lamini.generation.base_prompt_object import PromptObject #used for dataset formatting\n",
        "from lamini.generation.generation_pipeline import GenerationPipeline #used for finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2I32saSqpf2"
      },
      "outputs": [],
      "source": [
        "def setup_logging():\n",
        "    # Remove all handlers associated with the root logger object.\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.WARNING,\n",
        "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "        handlers=[logging.StreamHandler()],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y5Tfrvmq0w7"
      },
      "outputs": [],
      "source": [
        "def get_default_finetune_args():\n",
        "    return {\n",
        "        \"max_step\": 50,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQiz0XLjq5Lt"
      },
      "outputs": [],
      "source": [
        "def make_llama_3_prompt(user, system=\"\"):\n",
        "    system_prompt = \"\"\n",
        "    if system != \"\":\n",
        "        system_prompt = (\n",
        "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
        "        )\n",
        "    return f\"<|begin_of_text|>{system_prompt}<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maxI5TMkqgyE"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "setup_logging()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRC14nir2s_Z"
      },
      "outputs": [],
      "source": [
        "lamini.api_key = \"303a61ee9d5b19b4ed826d184dedef1b1b8a1c14df4a00cc7a74adfd19c899c4\"\n",
        "\n",
        "# instantiate the model with name from huggingface\n",
        "llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "50e6aa4446a84b5684cc926461f2379d",
            "7c6fc2beb45a4e99afd14093257882f2",
            "696dedc3b6cc46ea9bcc7f478371eb7e"
          ]
        },
        "id": "zWfzPsHelTjc",
        "outputId": "69948a04-e742-4848-fa60-c8b2281eef8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50e6aa4446a84b5684cc926461f2379d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/6.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c6fc2beb45a4e99afd14093257882f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/83.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "696dedc3b6cc46ea9bcc7f478371eb7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"openai_humaneval\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s3C0UGtt6vs"
      },
      "outputs": [],
      "source": [
        "split_dataset = dataset.train_test_split(test_size=0.207,seed=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-ZBSHhZuUmJ"
      },
      "outputs": [],
      "source": [
        "train_dataset = split_dataset['train']\n",
        "test_dataset = split_dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WALULvCAomhd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def format_prompt_and_test(example):\n",
        "  \"\"\"Formats the prompt and test sections of an example to only include the code after the function definition.\n",
        "\n",
        "  Args:\n",
        "    example: A dictionary representing an example.\n",
        "\n",
        "  Returns:\n",
        "    A new dictionary with the formatted prompt and test sections.\n",
        "  \"\"\"\n",
        "\n",
        "  # Extract the function name from the prompt\n",
        "  function_name_match = re.search(r\"def (\\w+)\\(\", example['prompt'])\n",
        "  if not function_name_match:\n",
        "    raise ValueError(\"Could not find function name in prompt.\")\n",
        "  function_name = function_name_match.group(1)\n",
        "\n",
        "  # Remove everything before the function definition in the prompt\n",
        "  prompt_index = example['prompt'].index(function_name)\n",
        "  example['prompt'] = \"def \" + example['prompt'][prompt_index:]\n",
        "\n",
        "  # Extract the test function name from the test section\n",
        "  test_function_name_match = re.search(r\"def (\\w+)\\(\", example['test'])\n",
        "  if not test_function_name_match:\n",
        "    raise ValueError(\"Could not find test function name in test.\")\n",
        "  test_function_name = test_function_name_match.group(1)\n",
        "\n",
        "  # Remove everything before the test function definition in the test section\n",
        "  test_index = example['test'].index(test_function_name)\n",
        "  example['test'] = \"def \" + example['test'][test_index:]\n",
        "\n",
        "\n",
        "\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aa8567529579491697116d6c6e4b7993"
          ]
        },
        "id": "fyxNaWt138fu",
        "outputId": "bd5942e3-727c-49e5-e398-57eb92deea24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa8567529579491697116d6c6e4b7993",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "updated_dataset = train_dataset.map(format_prompt_and_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjre1PBp5t_z"
      },
      "outputs": [],
      "source": [
        "# num = 90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQz6fwU-wVuz"
      },
      "outputs": [],
      "source": [
        "# print(updated_dataset[num]['prompt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_Pw0v0E5xI0"
      },
      "outputs": [],
      "source": [
        "# print(updated_dataset[num]['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq7fEDvy2s0K"
      },
      "outputs": [],
      "source": [
        "def make_question(obj):\n",
        "    system = \"You are a docstring to test generator\\n\"\n",
        "    system += (\n",
        "        \"Generate exactly 5 test cases for the following function:\"\n",
        "    )\n",
        "    user = obj[\"prompt\"]\n",
        "    return {\"system\": system, \"user\": user}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og7CYNkZ2sp7"
      },
      "outputs": [],
      "source": [
        "def make_llama_3_prompt(user, system=\"\"):\n",
        "    system_prompt = \"\"\n",
        "    if system != \"\":\n",
        "        system_prompt = (\n",
        "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
        "        )\n",
        "    return f\"<|begin_of_text|>{system_prompt}<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wt5yZ7D2skE"
      },
      "outputs": [],
      "source": [
        "def load_training_data(input_dataset,make_question):\n",
        "    for obj in input_dataset:\n",
        "        yield {\n",
        "            \"input\": make_llama_3_prompt(**make_question(obj)),\n",
        "            \"output\": obj[\"test\"] + \"<|eot_id|>\",\n",
        "            }\n",
        "\n",
        "def get_dataset(input_dataset, make_question):\n",
        "    dataset = list(load_training_data(input_dataset, make_question))\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g21pVq442sel"
      },
      "outputs": [],
      "source": [
        "ft_dataset = get_dataset(updated_dataset, make_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqZ6zH7Q2sP5"
      },
      "outputs": [],
      "source": [
        "finetune_args = get_default_finetune_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXOMhMXfkDiE"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# def save_as_jsonl(data, filename):\n",
        "#   \"\"\"Saves a list of dictionaries as a JSONL file.\n",
        "\n",
        "#   Args:\n",
        "#     data: A list of dictionaries to be saved.\n",
        "#     filename: The name of the JSONL file to be created.\n",
        "#   \"\"\"\n",
        "\n",
        "#   with open(filename, 'w') as f:\n",
        "#     for item in data:\n",
        "#       json.dump(item, f)\n",
        "#       f.write('\\n')\n",
        "#   print(\"done\")\n",
        "\n",
        "# save_as_jsonl(ft_dataset, 'data.jsonl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6uUrJwu2sAa"
      },
      "outputs": [],
      "source": [
        "# llm.train(\n",
        "#    data_or_dataset_id=ft_dataset,\n",
        "#    finetune_args=finetune_args,\n",
        "#    is_public=True,  # For sharing\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcSmRh1mrziC"
      },
      "outputs": [],
      "source": [
        "lamini.api_key = \"71e216caf7b4ee2358e0b64f8db9f0a7f7373dca1c4f71c696f35d4d7aff0b54\" #\"303a61ee9d5b19b4ed826d184dedef1b1b8a1c14df4a00cc7a74adfd19c899c4\"\n",
        "\n",
        "llm = lamini.Lamini(model_name=\"7cf4f7f9b53b1d4e616d48c3b554397177b5fc14d020d2255f33777876677f9d\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIJU5vaozso_"
      },
      "outputs": [],
      "source": [
        "system = \"You are a docstring to unit test generator\\n\"\n",
        "system += \"You analyse the docstring for a python function then use the understanding from that to develop a unit test\"\n",
        "system += (\n",
        "    \"Write a unit test that would help  determine if the function works as intended:\\n\"\n",
        "    \"Not more than 5 assert, You are to generate exactly 5 assert\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKXsQWyZXFtv"
      },
      "outputs": [],
      "source": [
        "system = \"\"\"\n",
        "Generate exactly 5 test cases\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Wcb3OaZh7M"
      },
      "outputs": [],
      "source": [
        "nums = [10, ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZxxrGf2aRGC"
      },
      "outputs": [],
      "source": [
        "# print(test_dataset[2]['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHaq3tFtV0Av",
        "outputId": "1c685049-8ce8-4d92-ac9c-db50f4f82cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Generate just 5 test cases\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "from typing import List\n",
            "\n",
            "\n",
            "def all_prefixes(string: str) -> List[str]:\n",
            "    \"\"\" Return list of all prefixes from shortest to longest of the input string\n",
            "    >>> all_prefixes('abc')\n",
            "    ['a', 'ab', 'abc']\n",
            "    \"\"\"\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = test_dataset[10]['prompt']\n",
        "prompt = make_llama_3_prompt(question, system)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yai5hOys9sAn",
        "outputId": "57fd7637-26c1-4e65-f8a5-d2feeb6bab95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def check(candidate):\n",
            "    assert candidate('') == []\n",
            "    assert candidate('asdfgh') == ['a', 'as', 'asd', 'asdf', 'asdfg', 'asdfgh']\n",
            "    assert candidate('WWW') == ['W', 'WW', 'WWW']\n",
            "    assert candidate('xywywx') == ['x', 'xy', 'xyw', 'xywy', 'xywyw', 'xywywx']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "answer = llm.generate(prompt)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO7O3Y6vPSe9"
      },
      "outputs": [],
      "source": [
        "def run_all_test_data(test_dataset):\n",
        "    predictions = []\n",
        "    for num in tqdm(range(len(test_dataset))):\n",
        "        question = test_dataset[num]['prompt']\n",
        "        prompt = make_llama_3_prompt(question, system)\n",
        "        answer = llm.generate(prompt)\n",
        "        predictions.append(answer)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPMkXXjJPSR4"
      },
      "outputs": [],
      "source": [
        "test_predictions = run_all_test_data(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz6TzKlRKIT2"
      },
      "outputs": [],
      "source": [
        "print(test_predictions[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6yAtSBXZNUO"
      },
      "source": [
        "#### Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5XwswrVe9rD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AT0DkU2Y_RX"
      },
      "source": [
        "#### Continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw7NilqR_LB0"
      },
      "outputs": [],
      "source": [
        "# num = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOvnNANOzs3b"
      },
      "outputs": [],
      "source": [
        "# question = test_dataset[num]['prompt']\n",
        "# prompt = make_llama_3_prompt(question, system)\n",
        "# print(\"Question:\\n\", question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj1UqH0a2SwL"
      },
      "outputs": [],
      "source": [
        "# print(\"Answer:\")\n",
        "# print(llm.generate(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18yo6Nzce91N"
      },
      "outputs": [],
      "source": [
        "# print(test_dataset[num]['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O-0haKizsgo"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import sys\n",
        "import re\n",
        "from io import StringIO\n",
        "\n",
        "def is_valid_python(code_string):\n",
        "    try:\n",
        "        ast.parse(code_string)\n",
        "        return True\n",
        "    except SyntaxError:\n",
        "        return False\n",
        "\n",
        "def run_python_code(code_string):\n",
        "    if not is_valid_python(code_string):\n",
        "        print(\"Invalid Python code\")\n",
        "        return False, \"Invalid Python code\"\n",
        "\n",
        "    # Redirect stdout to capture print outputs\n",
        "    old_stdout = sys.stdout\n",
        "    redirected_output = sys.stdout = StringIO()\n",
        "\n",
        "    try:\n",
        "        exec(code_string)\n",
        "        output = redirected_output.getvalue()\n",
        "        return True, output\n",
        "    except Exception as e:\n",
        "        print(f\"Runtime error: {str(e)}\")\n",
        "        return False, f\"Runtime error: {str(e)}\"\n",
        "    finally:\n",
        "        sys.stdout = old_stdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLQpf0ZL872K"
      },
      "outputs": [],
      "source": [
        "def get_function_name_from_string(code):\n",
        "    \"\"\"\n",
        "    Extracts the function name from a Python code string.\n",
        "\n",
        "    Args:\n",
        "        code: The Python code string.\n",
        "\n",
        "    Returns:\n",
        "        str: The function name, or None if not found.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        ast_tree = ast.parse(code)\n",
        "        for node in ast_tree.body:\n",
        "            if isinstance(node, ast.FunctionDef):\n",
        "                return node.name\n",
        "    except SyntaxError:\n",
        "        # Handle potential syntax errors in the code\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ba7I4vQ5BEY"
      },
      "outputs": [],
      "source": [
        "def extract_arguments_and_results(code):\n",
        "  \"\"\"Extracts arguments and expected results from assert statements in code.\"\"\"\n",
        "  pattern = r\"assert candidate\\((.*)\\) == (.*)\"\n",
        "  matches = re.findall(pattern, code)\n",
        "  return [(match[0], match[1]) for match in matches]\n",
        "\n",
        "def clean_string(s):\n",
        "    \"\"\"Remove escape characters and strip unnecessary whitespaces from a string.\"\"\"\n",
        "    # Remove escape characters like \\n, \\t, \\r, \\\\\n",
        "    s = s.encode('unicode_escape').decode('unicode_escape')\n",
        "    # Remove leading/trailing whitespaces and condense multiple spaces\n",
        "    return re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "def extract_assertions(code: str):\n",
        "    # Regular expression to capture the candidate function's argument and expected result\n",
        "    pattern = r\"assert\\s+candidate\\((.*?)\\)\\s*==\\s*((\\[.*?\\]|\\(.*?\\)|\\{.*?\\}|'.*?'|\\\".*?\\\"|True|False|\\d+))\"\n",
        "    matches = re.findall(pattern, code, re.DOTALL)\n",
        "\n",
        "    extracted = []\n",
        "    for match in matches:\n",
        "        arg = clean_string(match[0].strip())  # Clean the argument\n",
        "        result = clean_string(match[1].strip())  # Clean the expected result\n",
        "        extracted.append((arg, result))\n",
        "\n",
        "    return extracted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPCO0-0xZkWS"
      },
      "outputs": [],
      "source": [
        "def remove_last_line(text):\n",
        "  \"\"\"Removes the last line from a given text string.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The text string with the last line removed.\n",
        "  \"\"\"\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  if lines:\n",
        "    return '\\n'.join(lines[:-1])\n",
        "  else:\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0YuxaGw8jxF"
      },
      "outputs": [],
      "source": [
        "func = test_dataset['prompt'][4] + test_dataset['canonical_solution'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Hdw354AfJe"
      },
      "outputs": [],
      "source": [
        "function_name = get_function_name_from_string(func)\n",
        "print(function_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ksdBeOg65A5z"
      },
      "outputs": [],
      "source": [
        "args_and_results1 = extract_arguments_and_results(test_predictions[4])\n",
        "args_and_results2 = extract_arguments_and_results(test_predictions[12])\n",
        "\n",
        "print(\"Function 1:\")\n",
        "for args, result in args_and_results1:\n",
        "  print(f\"Args: {args}, Expected Result: {result}\")\n",
        "\n",
        "print(\"\\nFunction 2:\")\n",
        "for args, result in args_and_results2:\n",
        "  print(f\"Args: {args}, Expected Result: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "317vlH12Z8Cc"
      },
      "outputs": [],
      "source": [
        "num = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Prci2X9zsYP"
      },
      "outputs": [],
      "source": [
        "extract_assertions(test_predictions[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9oGCz541cLs"
      },
      "outputs": [],
      "source": [
        "extract_arguments_and_results(test_predictions[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iOtJSL0Y1e2"
      },
      "outputs": [],
      "source": [
        "print(test_dataset[\"prompt\"][num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdizSAbs87uu"
      },
      "outputs": [],
      "source": [
        "print(remove_last_line(test_predictions[num]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZob1g9lPok5"
      },
      "outputs": [],
      "source": [
        "# print(extract_arguments_and_results(remove_last_line(test_predictions[5])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMkrj9TW_Ju7"
      },
      "source": [
        "EVALUATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-MQutM__hJr",
        "outputId": "8e7ff3bf-7787-434b-eb4f-be0622997fc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/34 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 2038.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 33/33 [00:00<00:00, 2995.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 13/13 [00:00<00:00, 4420.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 7/7 [00:55<00:00,  7.97s/it]\n",
            " 12%|█▏        | 4/34 [00:55<06:58, 13.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 13/13 [00:00<00:00, 2386.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 13/13 [00:00<00:00, 2957.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 1005.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 2426.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 12/12 [00:00<00:00, 1420.07it/s]\n",
            " 26%|██▋       | 9/34 [00:55<02:05,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  8\n",
            "Current index: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 16/16 [00:00<00:00, 1918.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  9\n",
            "Current index: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:00<00:00, 2228.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  10\n",
            "Current index: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 1192.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 3286.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 36/36 [00:00<00:00, 4178.63it/s]\n",
            " 41%|████      | 14/34 [00:56<00:52,  2.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 2716.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  14\n",
            "Current index: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 35/35 [00:00<00:00, 1831.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 9/9 [00:00<00:00, 2521.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 3/3 [00:00<00:00, 1959.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  17\n",
            "Current index: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 16/16 [00:00<00:00, 1797.33it/s]\n",
            " 56%|█████▌    | 19/34 [00:56<00:23,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "Current index: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 14/14 [00:00<00:00, 2892.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 1899.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 3598.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 4/4 [00:00<00:00, 2902.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 14/14 [00:00<00:00, 1505.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid Python code\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n",
            "status csme back False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\r 71%|███████   | 24/34 [00:56<00:10,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 13/13 [00:00<00:00, 2355.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 7/7 [00:00<00:00, 1734.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  25\n",
            "Current index: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [00:00<00:00, 1588.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  26\n",
            "Current index: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 4/4 [00:00<00:00, 2181.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "complete match index  27\n",
            "Current index: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|▋         | 2/30 [00:00<00:01, 19.84it/s]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:00<00:01, 15.89it/s]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:00<00:00, 25.08it/s]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:00<00:00, 21.90it/s]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:00<00:00, 16.97it/s]\u001b[A\n",
            " 60%|██████    | 18/30 [00:01<00:00, 15.48it/s]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:01<00:00, 15.39it/s]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:01<00:00, 15.07it/s]\u001b[A\n",
            " 80%|████████  | 24/30 [00:01<00:00, 12.60it/s]\u001b[A\n",
            " 87%|████████▋ | 26/30 [00:01<00:00, 10.93it/s]\u001b[A\n",
            " 93%|█████████▎| 28/30 [00:02<00:00,  9.73it/s]\u001b[A\n",
            "100%|██████████| 30/30 [00:02<00:00, 13.14it/s]\n",
            " 85%|████████▌ | 29/34 [00:58<00:04,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 6/6 [00:00<00:00, 2333.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 12/12 [00:00<00:00, 1600.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 4028.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 37/37 [00:00<00:00, 778.73it/s]\n",
            " 97%|█████████▋| 33/34 [00:58<00:00,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current index: 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 2829.93it/s]\n",
            "100%|██████████| 34/34 [00:58<00:00,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'True': 31, 'False': 3}\n",
            "{'True': 8, 'False': 26}\n",
            "Valid code: 0.9117647058823529\n",
            "Model accuracy: 0.23529411764705882\n",
            "[{'True': 6, 'False': 4}, {'True': 6, 'False': 27}, {'True': 10, 'False': 3}, {'True': 3, 'False': 4}, {'True': 12, 'False': 1}, {'True': 12, 'False': 1}, {'True': 2, 'False': 8}, {'True': 7, 'False': 2}, {'True': 12, 'False': 0}, {'True': 16, 'False': 0}, {'True': 5, 'False': 0}, {'True': 2, 'False': 4}, {'True': 19, 'False': 1}, {'True': 2, 'False': 34}, {'True': 8, 'False': 0}, {'True': 2, 'False': 33}, {'True': 6, 'False': 3}, {'True': 3, 'False': 0}, {'True': 1, 'False': 15}, {'True': 5, 'False': 9}, {'True': 3, 'False': 15}, {'True': 9, 'False': 15}, {'True': 2, 'False': 2}, {'True': 2, 'False': 12}, {'True': 1, 'False': 12}, {'True': 7, 'False': 0}, {'True': 10, 'False': 0}, {'True': 4, 'False': 0}, {'True': 21, 'False': 9}, {'True': 0, 'False': 6}, {'True': 1, 'False': 11}, {'True': 9, 'False': 2}, {'True': 6, 'False': 31}, {'True': 4, 'False': 4}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "code_validity = {\n",
        "    \"True\": 0,\n",
        "    \"False\": 0\n",
        "}\n",
        "\n",
        "model_accuracy = {\n",
        "    \"True\": 0,\n",
        "    \"False\": 0\n",
        "}\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "#loop the test\n",
        "for i in tqdm(range(len(test_predictions))):\n",
        "# for i in tqdm(range(10,len(test_predictions))):\n",
        "\n",
        "    print(\"Current index:\",i)\n",
        "    #check if the function is valid\n",
        "    test_case = test_predictions[i]\n",
        "\n",
        "    #remove the last line\n",
        "    test_case = remove_last_line(test_case)\n",
        "\n",
        "    #check if the function is valid\n",
        "    state = str(is_valid_python(test_case)).strip()\n",
        "\n",
        "    #increase the state\n",
        "    code_validity[state] += 1\n",
        "\n",
        "    if state:\n",
        "        #get the main function\n",
        "        func = test_dataset['prompt'][i] + test_dataset['canonical_solution'][i]\n",
        "\n",
        "        #get the name of the function\n",
        "        function_name = get_function_name_from_string(func)\n",
        "\n",
        "        #get all the args from the test generated\n",
        "        args_and_results = extract_assertions(test_case) #extract_arguments_and_results(test_case)\n",
        "\n",
        "        accuracy = {\n",
        "            \"True\": 0,\n",
        "            \"False\": 0\n",
        "            }\n",
        "\n",
        "        # loop through all the arguement and expected results\n",
        "        for args, result in tqdm(args_and_results):\n",
        "            #run the python function and compare the result\n",
        "            code = f\"{func}\\n\\nresult={function_name}({args}) == {result}\\nprint(result, end='')\"\n",
        "            # print(code)\n",
        "            #get the status of the code and the corresponding output\n",
        "            status, output = run_python_code(code)\n",
        "            # print(\"Output\",output)\n",
        "            #check if the status is true or false\n",
        "            if status:\n",
        "                try:\n",
        "                    accuracy[output] += 1\n",
        "                except:\n",
        "                    if \"True\" in output:\n",
        "                        accuracy[\"True\"] += 1\n",
        "                    else:\n",
        "                        accuracy[\"False\"] += 1\n",
        "            else:\n",
        "                print(\"status csme back False\")\n",
        "                accuracy[\"False\"] += 1\n",
        "\n",
        "        if accuracy[\"True\"] == len(args_and_results):\n",
        "            print()\n",
        "            print(\"complete match index \", i)\n",
        "            model_accuracy[\"True\"] += 1\n",
        "        else:\n",
        "            model_accuracy[\"False\"] += 1\n",
        "\n",
        "        accuracy_list.append(accuracy)\n",
        "        # print(accuracy)\n",
        "        # print(model_accuracy)\n",
        "        # print(model_accuracy['None']) #this is just to force a crash\n",
        "    else:\n",
        "        model_accuracy[\"False\"] += 1\n",
        "        accuracy_list.append(None)\n",
        "\n",
        "print()\n",
        "print(code_validity)\n",
        "print(model_accuracy)\n",
        "\n",
        "print(f\"Valid code: {code_validity['True']/(code_validity['True'] + code_validity['False'])}\")\n",
        "print(f\"Model accuracy: {model_accuracy['True']/(model_accuracy['True'] + model_accuracy['False'])}\")\n",
        "\n",
        "print(accuracy_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE6UVcjjDYjt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQkGSpoRatn6",
        "outputId": "cddcba2c-9cd0-4dc2-dba7-0b185eee7c6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 34/34 [00:00<00:00, 3084.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'True': 12, 'False': 22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result = {\n",
        "    \"True\": 0,\n",
        "    \"False\": 0\n",
        "}\n",
        "\n",
        "for prediction in tqdm(test_predictions):\n",
        "    state = str(is_valid_python(prediction))\n",
        "    result[state] += 1\n",
        "\n",
        "print()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSXap797Pn6S"
      },
      "source": [
        "#Second trial with Code LLama\n",
        "\n",
        "\n",
        "https://github.com/ragntune/code-llama-finetune/blob/main/fine-tune-code-llama.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJf-mp09hZ59"
      },
      "outputs": [],
      "source": [
        "# %pip install -U transformers\n",
        "# %pip install -U datasets\n",
        "# %pip install -U accelerate\n",
        "# %pip install -U peft\n",
        "# %pip install -U trl\n",
        "# %pip install -U bitsandbytes\n",
        "# %pip install -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYzYZP0GheIP",
        "outputId": "58736573-fab9-4f62-eeda-0f2b4df07393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
            "Collecting git+https://github.com/huggingface/transformers.git@main\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-cwp7lgy7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-cwp7lgy7\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit b0f0c61899019d316db17a493023828aa44db06d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2.32.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n",
            "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=10034048 sha256=c54361b6e57ff2bb711a5adaed536bfa077cd6bac28fe7d67090349b5d2eb049\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sv4k2xl7/wheels/cf/59/82/6492402e887a68975030bf8c06532260abc16abb7ccd8127cc\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, bitsandbytes, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed bitsandbytes-0.44.1 tokenizers-0.20.1 transformers-4.46.0.dev0\n",
            "Collecting git+https://github.com/huggingface/peft.git@main\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision main) to /tmp/pip-req-build-5ft0w0yl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-5ft0w0yl\n",
            "  Resolved https://github.com/huggingface/peft.git to commit cff2a454ad0254ecdfcb9dfa3fac4abf2b4b9f09\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (4.46.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.13.3.dev0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.13.3.dev0) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.13.3.dev0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.13.3.dev0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.3.dev0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.13.3.dev0) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.13.3.dev0) (0.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.13.3.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.3.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.3.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.3.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.3.dev0) (2024.8.30)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.13.3.dev0-py3-none-any.whl size=340496 sha256=c0632b7f04e20ad5b88b9473da8f4453aac177dcd8fa3023afcf02efd61194af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0csbtpxt/wheels/c4/e1/51/d197b9c452a772de94f87f5783e2cf47b87eb428a02cf30a0d\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "Successfully installed peft-0.13.3.dev0\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install python dependencies\n",
        "!pip install tqdm nbformat\n",
        "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/peft.git@main\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-oszZxhZP0ff"
      },
      "outputs": [],
      "source": [
        "import locale # colab workaround\n",
        "locale.getpreferredencoding = lambda x=False:\"UTF-8\" # colab workaround"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9wc_tseP0TR"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_kbit_training,\n",
        "    set_peft_model_state_dict,\n",
        ")\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "08919f75e9e847e1820a9b22f67f50b6",
            "2f59c51ddf8b4066936e9d3c4eb02034",
            "53b379e6a32d41508e501e3e16336a9b"
          ]
        },
        "id": "BBC3TuyWUqyX",
        "outputId": "12678bab-033d-433c-81cc-e19c079c5de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08919f75e9e847e1820a9b22f67f50b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/6.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f59c51ddf8b4066936e9d3c4eb02034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/83.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53b379e6a32d41508e501e3e16336a9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"openai_humaneval\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2nSJXsUUqyZ"
      },
      "outputs": [],
      "source": [
        "split_dataset = dataset.train_test_split(test_size=0.207,seed=29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58p8-HniUqya"
      },
      "outputs": [],
      "source": [
        "train_dataset = split_dataset['train']\n",
        "test_dataset = split_dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "a721767877b34901a63e03921d41f20c",
            "7fb36ff6fe3d4d5c902389094975f346",
            "4fde5b2af27843709772bc11af0b260e",
            "d7a5d6a949894e5387db87f96d01e16f",
            "90120433b12f4f7880dc16c5bf8fe302",
            "b644dcda4e384d228bef302a54f396d4",
            "c7f7ec38bef340f395736d421d0b3fd1",
            "62218726177047f792316e721e7552d9",
            "5102bbe5ffff48b2aa36880a15b254a7",
            "39286fe9c563424dbdf9873ec6ca9cd5",
            "d474d65154244ef48f17947f9efdd2e6"
          ]
        },
        "id": "-wJ53xVqQmv9",
        "outputId": "9bbd9829-4cb7-4627-d3fd-90caa4b3ab7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a721767877b34901a63e03921d41f20c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fb36ff6fe3d4d5c902389094975f346",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fde5b2af27843709772bc11af0b260e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7a5d6a949894e5387db87f96d01e16f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90120433b12f4f7880dc16c5bf8fe302",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b644dcda4e384d228bef302a54f396d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f7ec38bef340f395736d421d0b3fd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62218726177047f792316e721e7552d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5102bbe5ffff48b2aa36880a15b254a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39286fe9c563424dbdf9873ec6ca9cd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d474d65154244ef48f17947f9efdd2e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_model = \"codellama/CodeLlama-7b-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MpEq9WwbSPj"
      },
      "outputs": [],
      "source": [
        "tokenizer.add_eos_token = True\n",
        "tokenizer.pad_token_id = 0\n",
        "tokenizer.padding_side = \"left\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9JvXL4Sbg0E"
      },
      "outputs": [],
      "source": [
        "def tokenize(prompt):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    # \"self-supervised learning\" means the labels are also the inputs:\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMZgTzPObgmp"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt =f\"\"\"You are a powerful docstring_text-to-unit_test model.\n",
        "    Your job is to generate unit tests from docstring.\n",
        "    You are given a docstring detailing what the function does.\n",
        "\n",
        "You must output the unit test that evaluates the function of the docstring.\n",
        "\n",
        "### Input:\n",
        "{data_point[\"prompt\"]}\n",
        "\n",
        "### Response:\n",
        "{data_point[\"test\"]}\n",
        "\"\"\"\n",
        "    return tokenize(full_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHAZVWETgNJr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def format_prompt_and_test(example):\n",
        "  \"\"\"Formats the prompt and test sections of an example to only include the code after the function definition.\n",
        "\n",
        "  Args:\n",
        "    example: A dictionary representing an example.\n",
        "\n",
        "  Returns:\n",
        "    A new dictionary with the formatted prompt and test sections.\n",
        "  \"\"\"\n",
        "\n",
        "  # Extract the function name from the prompt\n",
        "  function_name_match = re.search(r\"def (\\w+)\\(\", example['prompt'])\n",
        "  if not function_name_match:\n",
        "    raise ValueError(\"Could not find function name in prompt.\")\n",
        "  function_name = function_name_match.group(1)\n",
        "\n",
        "  # Remove everything before the function definition in the prompt\n",
        "  prompt_index = example['prompt'].index(function_name)\n",
        "  example['prompt'] = \"def \" + example['prompt'][prompt_index:]\n",
        "\n",
        "  # Extract the test function name from the test section\n",
        "  test_function_name_match = re.search(r\"def (\\w+)\\(\", example['test'])\n",
        "  if not test_function_name_match:\n",
        "    raise ValueError(\"Could not find test function name in test.\")\n",
        "  test_function_name = test_function_name_match.group(1)\n",
        "\n",
        "  # Remove everything before the test function definition in the test section\n",
        "  test_index = example['test'].index(test_function_name)\n",
        "  example['test'] = \"def \" + example['test'][test_index:]\n",
        "\n",
        "\n",
        "\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "85a92aaa4d9c447ba9b44d20b382c24e"
          ]
        },
        "id": "Ti1ehfJOgNJu",
        "outputId": "7408a2e6-72cf-4214-c700-25ea6b100164"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85a92aaa4d9c447ba9b44d20b382c24e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "updated_dataset = train_dataset.map(format_prompt_and_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5b2310c92b964fc189fe9687d6ed657d"
          ]
        },
        "id": "jn4_uBtegkQ0",
        "outputId": "74b84b19-cd78-4e90-b06a-2a1a32780b76"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b2310c92b964fc189fe9687d6ed657d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "updated_test_dataset = test_dataset.map(format_prompt_and_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f61067cec8da4127916069ea1da0f5f6",
            "016f2965994c46cd856e1acf53dc0346"
          ]
        },
        "id": "TtK5NBzxbgXi",
        "outputId": "00a95394-385e-4a6f-f212-a6f86588909b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f61067cec8da4127916069ea1da0f5f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "016f2965994c46cd856e1acf53dc0346",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train_dataset = updated_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = updated_test_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45fTRBjVbgJf"
      },
      "outputs": [],
      "source": [
        "model.train() # put model back into training mode\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "    \"q_proj\",\n",
        "    \"k_proj\",\n",
        "    \"v_proj\",\n",
        "    \"o_proj\",\n",
        "],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMHsemBSbf5n"
      },
      "outputs": [],
      "source": [
        "resume_from_checkpoint = \"\" # set this to the adapter_model.bin file you want to resume from\n",
        "\n",
        "if resume_from_checkpoint:\n",
        "    if os.path.exists(resume_from_checkpoint):\n",
        "        print(f\"Restarting from {resume_from_checkpoint}\")\n",
        "        adapters_weights = torch.load(resume_from_checkpoint)\n",
        "        set_peft_model_state_dict(model, adapters_weights)\n",
        "    else:\n",
        "        print(f\"Checkpoint {resume_from_checkpoint} not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX0H0RZSbfrH"
      },
      "outputs": [],
      "source": [
        "wandb_project = \"docstring-testcase-coder\"\n",
        "if len(wandb_project) > 0:\n",
        "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaGSDo5KhXzU"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1:\n",
        "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWtaJBVOhaxK",
        "outputId": "c1ce01bc-7f6c-4e86-a896-1e136264b6ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "per_device_train_batch_size = 4\n",
        "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
        "output_dir = \"docstring-testcase-llama\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        warmup_steps=100,\n",
        "        max_steps=100,\n",
        "        learning_rate=3e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_torch\",\n",
        "        evaluation_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=20,\n",
        "        save_steps=20,\n",
        "        output_dir=output_dir,\n",
        "        # save_total_limit=3,\n",
        "        load_best_model_at_end=False,\n",
        "        # ddp_find_unused_parameters=False if ddp else None,\n",
        "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
        "        report_to=\"wandb\", # if use_wandb else \"none\",\n",
        "        run_name=f\"codellama-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\", # if use_wandb else None,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeq2Seq(\n",
        "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QlXPcEZhncU",
        "outputId": "dec94438-bca6-47ed-e577-af92bfdea774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compiling the model\n"
          ]
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "\n",
        "old_state_dict = model.state_dict\n",
        "model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(\n",
        "    model, type(model)\n",
        ")\n",
        "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "    print(\"compiling the model\")\n",
        "    model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "O22oAindhs-X",
        "outputId": "034bcb28-9495-486e-d7fe-17e41be99a7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241023_214257-atm1744c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/daa238-cornell-university/docstring-testcase-coder/runs/atm1744c' target=\"_blank\">codellama-2024-10-23-21-36</a></strong> to <a href='https://wandb.ai/daa238-cornell-university/docstring-testcase-coder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/daa238-cornell-university/docstring-testcase-coder' target=\"_blank\">https://wandb.ai/daa238-cornell-university/docstring-testcase-coder</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/daa238-cornell-university/docstring-testcase-coder/runs/atm1744c' target=\"_blank\">https://wandb.ai/daa238-cornell-university/docstring-testcase-coder/runs/atm1744c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 30/100 2:13:13 < 5:33:02, 0.00 it/s, Epoch 28.12/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.498600</td>\n",
              "      <td>1.157373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 49/100 3:44:06 < 4:03:11, 0.00 it/s, Epoch 46.55/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.498600</td>\n",
              "      <td>1.157373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.540600</td>\n",
              "      <td>0.669509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv8RSs9yh0ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCmGK4woouq6"
      },
      "source": [
        "# Third Trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYKXlVT0owkN"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\" # this is needed to get rid of weird colab locale error\n",
        "# if you are still running into issues, please restart the runtime to initialize a new environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5QGDzObv6OR"
      },
      "outputs": [],
      "source": [
        "# https://github.com/evalplus/evalplus\n",
        "!pip install -q evalplus==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "lbcNEzFWxC3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import sys\n",
        "import re\n",
        "from io import StringIO\n",
        "\n",
        "def is_valid_python(code_string):\n",
        "    try:\n",
        "        ast.parse(code_string)\n",
        "        return True\n",
        "    except SyntaxError:\n",
        "        return False\n",
        "\n",
        "def run_python_code(code_string):\n",
        "    if not is_valid_python(code_string):\n",
        "        print(\"Invalid Python code\")\n",
        "        return False, \"Invalid Python code\"\n",
        "\n",
        "    # Redirect stdout to capture print outputs\n",
        "    old_stdout = sys.stdout\n",
        "    redirected_output = sys.stdout = StringIO()\n",
        "\n",
        "    try:\n",
        "        exec(code_string)\n",
        "        output = redirected_output.getvalue()\n",
        "        return True, output\n",
        "    except Exception as e:\n",
        "        # print(f\"Runtime error: {str(e)}\")\n",
        "        return False, f\"Runtime error: {str(e)}\"\n",
        "    finally:\n",
        "        sys.stdout = old_stdout"
      ],
      "metadata": {
        "id": "9JP5yG3eJpJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CXZ2J-1ygY0"
      },
      "outputs": [],
      "source": [
        "# obtain the humaneval dataset\n",
        "from evalplus.data import get_human_eval_plus\n",
        "\n",
        "dataset = get_human_eval_plus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-zUTul0b5vK"
      },
      "outputs": [],
      "source": [
        "# # feel free to play around the dataset to see what it looks like!\n",
        "# dataset.keys()\n",
        "\n",
        "# # keys folllow the format HumanEval/0, HumanEval/1, ..., HumanEval/163\n",
        "# dataset['HumanEval/0'].keys()\n",
        "# dict_keys(['task_id', 'prompt', 'entry_point',\n",
        "#            'canonical_solution', 'test', 'contract', 'base_input', 'atol', 'plus_input'])\n",
        "\n",
        "\n",
        "# dataset['HumanEval/0']['task_id'] #HumanEval/0\n",
        "\n",
        "# print(dataset['HumanEval/0']['prompt']) #returns the function and docstring\n",
        "\n",
        "# dataset['HumanEval/0']['entry_point'] #Returns name of function e.g has_close_elements\n",
        "\n",
        "# print(dataset['HumanEval/0']['canonical_solution']) #this is a possible solution\n",
        "\n",
        "# print(dataset['HumanEval/0']['test']) #Returns unit test to evaluate llm generation\n",
        "\n",
        "# print(dataset['HumanEval/0']['contract']) #used to test argument passed\n",
        "\n",
        "# print(dataset['HumanEval/0']['base_input']) #inputs used in the test function\n",
        "\n",
        "# dataset['HumanEval/0']['atol']\n",
        "\n",
        "# len(dataset['HumanEval/0']['plus_input']) # 999+ additional inputs for test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num = 7\n",
        "# function = dataset[f'HumanEval/{num}']['prompt'] + dataset[f'HumanEval/{num}']['canonical_solution']\n",
        "# code = (f\"{function}\\nresult = {dataset[f'HumanEval/{num}']['entry_point']}\"\n",
        "# f\"{tuple(dataset[f'HumanEval/{num}']['base_input'][1])}\\n\"\n",
        "# f\"response = {{\\\"result\\\": result,\\\"type\\\": type(result).__name__}}\\n\"\n",
        "# \"print(response, end ='')\")\n",
        "\n",
        "# # \"print(result, end ='')\")\n",
        "# print(code)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8nJhMvqv6-DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_python_code(code)"
      ],
      "metadata": {
        "id": "Ck-WCUD3m9YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ans = ast.literal_eval(run_python_code(code)[1])\n",
        "# eval(ans['type']+f\"({ans['result']})\")"
      ],
      "metadata": {
        "id": "AEXoLrreKF7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### generating new dataset"
      ],
      "metadata": {
        "id": "HvlB08CN33cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system = (\"You are a powerful docstring_text-to-unit_test model.\"\n",
        "\" Your job is to generate unit tests from docstring.\"\n",
        "\" You will be given a docstring detailing what the function does.\")"
      ],
      "metadata": {
        "id": "u1aD_giwMblX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "created_dataset = []\n",
        "error_numbers = []\n",
        "\n",
        "open_ai_dataset = []\n",
        "for i in range(134):\n",
        "  data = {}\n",
        "  random_number = random.choice([5, 7, 9,11])\n",
        "  inputs = dataset[f'HumanEval/{i}']['base_input']+dataset[f'HumanEval/{i}']['plus_input']\n",
        "\n",
        "  data['system'] = system\n",
        "  data['prompt'] = (f\"Generate exactly {random_number} test cases for the following function\\n\\n\"\n",
        "  f\"'''\\n{dataset[f'HumanEval/{i}']['prompt']}'''\")\n",
        "\n",
        "  test = \"\"\n",
        "  should_process = True\n",
        "  for j in range(random_number):\n",
        "    if j == 0:\n",
        "      test += \"def check(candidate):\\n\"\n",
        "\n",
        "    #get the base input\n",
        "    base_input = inputs[j]\n",
        "    #get the length of the base input\n",
        "    input_len = len(base_input)\n",
        "\n",
        "    function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "\n",
        "    code = (f\"{function}\\n\"\n",
        "    f\"result = {dataset[f'HumanEval/{i}']['entry_point']}{tuple(base_input)}\\n\"\n",
        "    f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "    \"print(response, end ='')\")\n",
        "\n",
        "    result = run_python_code(code)\n",
        "    if result[0] ==  False:\n",
        "      should_process = False\n",
        "      print(\"Skipped number \", i)\n",
        "      error_numbers.append(i)\n",
        "      break\n",
        "\n",
        "    result = ast.literal_eval(result[1])\n",
        "    if result['type'] == 'str':\n",
        "      test += f\"    assert candidate{tuple(base_input)} == '{result['result']}'\\n\"\n",
        "    else:\n",
        "      test += f\"    assert candidate{tuple(base_input)} == {result['result']}\\n\"\n",
        "\n",
        "  if should_process:\n",
        "    data['test'] = test\n",
        "    openai_data = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": data['prompt']},\n",
        "            {\"role\": \"assistant\", \"content\": data['test']}\n",
        "        ]\n",
        "    }\n",
        "    open_ai_dataset.append(openai_data)\n",
        "    created_dataset.append(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPIPufL1Bbd",
        "outputId": "c364b0c7-22a5-4883-c8df-979a71cebc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped number  10\n",
            "Skipped number  32\n",
            "Skipped number  115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skipped number  10  \n",
        "Skipped number  32  \n",
        "Skipped number  115  "
      ],
      "metadata": {
        "id": "gEe3R1OXvd71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# # File to save the JSON Lines data\n",
        "# file_path = \"cs6158_data.jsonl\"\n",
        "\n",
        "# # Save the list of dictionaries into a JSONL file\n",
        "# with open(file_path, 'w') as jsonl_file:\n",
        "#     for record in created_dataset:\n",
        "#         jsonl_file.write(json.dumps(record) + '\\n')\n",
        "\n",
        "# print(f\"Data saved to {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VVMBpeDtDKT",
        "outputId": "5f4ad15a-b3ee-44ca-b648-ca6ec2deefb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to cs6158_openai_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsNLIqO_1BRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### finetuning"
      ],
      "metadata": {
        "id": "H3LM-eb_xH6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lamini==3.1.0 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF5GzKDtxsDe",
        "outputId": "6cb32c5c-bab0-4985-cb33-8d81b17f7abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'lamini' candidate (version 3.1.0 at https://files.pythonhosted.org/packages/48/84/dfcac72e22223ec30b8e4b51494c0a6c95eba16bd08df53ee396a409a404/lamini-3.1.0-8-py3-none-any.whl (from https://pypi.org/simple/lamini/) (requires-python:>=3.7))\n",
            "Reason for being yanked: implement forwards compat\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/691.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m686.1/691.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.0/691.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/408.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmIb0kERyBI9"
      },
      "outputs": [],
      "source": [
        "import lamini #used to pull our LLm for finetuning\n",
        "import logging #used for logging our flows\n",
        "from datetime import datetime\n",
        "from pprint import pprint #for pretty printing\n",
        "from typing import AsyncIterator, Iterator, Union #used for static casting\n",
        "from tqdm import tqdm #used to show loop progress\n",
        "import pandas as pd #used for data manipulations\n",
        "import jsonlines #used for dataset formatting\n",
        "\n",
        "from lamini.generation.generation_node import GenerationNode #used for the finetuning\n",
        "from lamini.generation.base_prompt_object import PromptObject #used for dataset formatting\n",
        "from lamini.generation.generation_pipeline import GenerationPipeline #used for finetuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "CkLiZXW2yHef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5WvcnJyyBI_"
      },
      "outputs": [],
      "source": [
        "def setup_logging():\n",
        "    # Remove all handlers associated with the root logger object.\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.WARNING,\n",
        "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "        handlers=[logging.StreamHandler()],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfpYXw6tyBJA"
      },
      "outputs": [],
      "source": [
        "def get_default_finetune_args():\n",
        "    return {\n",
        "        \"max_step\": 50,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaHiEJGYyBJA"
      },
      "outputs": [],
      "source": [
        "def make_llama_3_prompt(user, system=\"\"):\n",
        "    system_prompt = \"\"\n",
        "    if system != \"\":\n",
        "        system_prompt = (\n",
        "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
        "        )\n",
        "    return f\"<|begin_of_text|>{system_prompt}<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lym5bLtcyBJB"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "setup_logging()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9chu9k0IyBJB"
      },
      "outputs": [],
      "source": [
        "lamini.api_key = userdata.get('lamini.api_key')\n",
        "\n",
        "# instantiate the model with name from huggingface\n",
        "llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_question(obj):\n",
        "    system = obj['system']\n",
        "    user = obj[\"prompt\"]\n",
        "    return {\"system\": system, \"user\": user}"
      ],
      "metadata": {
        "id": "TqVLFBkcxsZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_data(input_dataset,make_question):\n",
        "    for obj in input_dataset:\n",
        "        yield {\n",
        "            \"input\": make_llama_3_prompt(**make_question(obj)),\n",
        "            \"output\": obj[\"test\"] + \"<|eot_id|>\",\n",
        "            }\n",
        "\n",
        "def get_dataset(input_dataset, make_question):\n",
        "    dataset = list(load_training_data(input_dataset, make_question))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "mdbwBAAK08Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(created_dataset, make_question)"
      ],
      "metadata": {
        "id": "pZKtaiiR1Nzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_args = get_default_finetune_args()"
      ],
      "metadata": {
        "id": "UAL0i1vs1bVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "m8Qi_j_b2LPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm.train(\n",
        "#     data_or_dataset_id=train_dataset,\n",
        "#     finetune_args=finetune_args,\n",
        "#     is_public=False\n",
        "#   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsXzAO4a13ay",
        "outputId": "81380da3-d673-4845-e02c-0f1ada3cce7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data pairs uploaded to local.\n",
            "\n",
            "Your dataset id is: bca8887029165275e79793c605ecf5c7124b27021f183bad02f0332311e1cc94 . Consider using this in the future to train using the same data. \n",
            "Eg: llm.train(data_or_dataset_id='bca8887029165275e79793c605ecf5c7124b27021f183bad02f0332311e1cc94')\n",
            "EXISTING DATA 303a61ee9d5b19b4ed826d184dedef1b1b8a1c14df4a00cc7a74adfd19c899c4\n",
            "Tuning job submitted! Check status of job 14366 here: https://api.lamini.ai/train/14366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'job_id': 14366,\n",
              " 'status': 'CREATED',\n",
              " 'dataset_id': 'bca8887029165275e79793c605ecf5c7124b27021f183bad02f0332311e1cc94'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = lamini.Lamini(model_name=\"137d66b210823d2c142ce7f096fc26303b446ba5bceb74683a640b06584bb6b9\")"
      ],
      "metadata": {
        "id": "UOjMO1Cs13Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = f\"\"\"Generate Exactly 9 test cases for this function\n",
        "```{dataset['HumanEval/134']['prompt']}```\n",
        "\"\"\"\n",
        "prompt = make_llama_3_prompt(question, system)\n",
        "print(\"Question:\\n\", prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuihAgLp13Ml",
        "outputId": "4ec1c9c8-7bc9-4c34-8dd7-c633edd1e4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a powerful docstring_text-to-unit_test model. Your job is to generate unit tests from docstring. You will be given a docstring detailing what the function does.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Generate Exactly 9 test cases for this function\n",
            "```\n",
            "def check_if_last_char_is_a_letter(txt):\n",
            "    '''\n",
            "    Create a function that returns True if the last character\n",
            "    of a given string is an alphabetical character and is not\n",
            "    a part of a word, and False otherwise.\n",
            "    Note: \"word\" is a group of characters separated by space.\n",
            "\n",
            "    Examples:\n",
            "    check_if_last_char_is_a_letter(\"apple pie\") ➞ False\n",
            "    check_if_last_char_is_a_letter(\"apple pi e\") ➞ True\n",
            "    check_if_last_char_is_a_letter(\"apple pi e \") ➞ False\n",
            "    check_if_last_char_is_a_letter(\"\") ➞ False \n",
            "    '''\n",
            "```\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Answer:\")\n",
        "answer = llm.generate(prompt, max_new_tokens=1000)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX47VnBn3CM_",
        "outputId": "c40486ca-f8a7-4b6a-b286-15e38467db0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "def check(candidate):\n",
            "    assert candidate('apple pie',) == False\n",
            "    assert candidate('apple pi e',) == True\n",
            "    assert candidate('apple pi e ',) == False\n",
            "    assert candidate('',) == False\n",
            "    assert candidate('abc',) == True\n",
            "    assert candidate('123',) == False\n",
            "    assert candidate('abc!',) == True\n",
            "    assert candidate('abc! ',) == False\n",
            "    assert candidate('abc!!',) == True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_valid_python(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SGnYnqd3CCe",
        "outputId": "82790c6b-97be-4e19-fee0-482f6e75c2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EVALUATION"
      ],
      "metadata": {
        "id": "bRi0NMtj490F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### before evaluating make sure that the code is runnable"
      ],
      "metadata": {
        "id": "eRs7UqwKuzoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = []\n",
        "error_numbers = []\n",
        "\n",
        "for i in range(134,164):\n",
        "  data = {}\n",
        "  random_number = random.choice([5, 7, 9,11])\n",
        "  inputs = dataset[f'HumanEval/{i}']['base_input']+dataset[f'HumanEval/{i}']['plus_input']\n",
        "\n",
        "  data['system'] = system\n",
        "  data['prompt'] = (f\"Generate exactly {random_number} test cases for the following function\\n\\n\"\n",
        "  f\"'''\\n{dataset[f'HumanEval/{i}']['prompt']}'''\")\n",
        "\n",
        "  test = \"\"\n",
        "  should_process = True\n",
        "  for j in range(random_number):\n",
        "    if j == 0:\n",
        "      test += \"def check(candidate):\\n\"\n",
        "\n",
        "    #get the base input\n",
        "    base_input = inputs[j]\n",
        "    #get the length of the base input\n",
        "    input_len = len(base_input)\n",
        "\n",
        "    function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "\n",
        "    code = (f\"{function}\\n\"\n",
        "    f\"result = {dataset[f'HumanEval/{i}']['entry_point']}{tuple(base_input)}\\n\"\n",
        "    f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "    \"print(response, end ='')\")\n",
        "\n",
        "    result = run_python_code(code)\n",
        "    if result[0] ==  False:\n",
        "      should_process = False\n",
        "      print(\"Skipped number \", i)\n",
        "      error_numbers.append(i)\n",
        "      break\n",
        "\n",
        "    result = ast.literal_eval(result[1])\n",
        "    if result['type'] == 'str':\n",
        "      test += f\"    assert candidate{tuple(base_input)} == '{result['result']}'\\n\"\n",
        "    else:\n",
        "      test += f\"    assert candidate{tuple(base_input)} == {result['result']}\\n\"\n",
        "\n",
        "  if should_process:\n",
        "    data['test'] = test\n",
        "    test_dataset.append(data)"
      ],
      "metadata": {
        "id": "YXoe9KyRu1zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in test_dataset:\n",
        "#   print(data['test'])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yEU2AAR25dCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Some clean up"
      ],
      "metadata": {
        "id": "UzmW1PcfxpdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[f'HumanEval/{137}']['test'] = \"\"\"\n",
        "def check(candidate):\n",
        "    # Check some simple cases\n",
        "    assert candidate(1, 2) == 2\n",
        "    assert candidate(1, 2.5) == 2.5\n",
        "    assert candidate(2, 3) == 3\n",
        "    assert candidate(5, 6) == 6\n",
        "    assert candidate(1, \"2,3\") == \"2,3\"\n",
        "    assert candidate(\"5,1\", \"6\") == \"6\"\n",
        "    assert candidate(\"1\", \"2\") == \"2\"\n",
        "    assert candidate(\"1\", 1) == None\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GZpwUozsxQpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper functions for evaluations"
      ],
      "metadata": {
        "id": "y1A22yqX6H2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def clean_string(s):\n",
        "#     \"\"\"Remove escape characters and strip unnecessary whitespaces from a string.\"\"\"\n",
        "#     # Remove escape characters like \\n, \\t, \\r, \\\\\n",
        "#     s = s.encode('unicode_escape').decode('unicode_escape')\n",
        "#     # Remove leading/trailing whitespaces and condense multiple spaces\n",
        "#     return re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "# def extract_assertions(code: str):\n",
        "#     # Updated regular expression to capture candidate function's argument and expected result\n",
        "#     # Now includes support for None, negative numbers, and various data types\n",
        "#     pattern = r\"assert\\s+candidate\\((.*?)\\)\\s*==\\s*((\\[.*?\\]|\\(.*?\\)|\\{.*?\\}|'.*?'|\\\".*?\\\"|True|False|None|-?\\d+))\"\n",
        "#     matches = re.findall(pattern, code, re.DOTALL)\n",
        "\n",
        "#     extracted = []\n",
        "#     for match in matches:\n",
        "#         arg = clean_string(match[0].strip())  # Clean the argument\n",
        "#         result = clean_string(match[1].strip())  # Clean the expected result\n",
        "#         extracted.append((arg, result))\n",
        "\n",
        "#     return extracted\n",
        "\n",
        "\n",
        "def clean_string(s):\n",
        "    \"\"\"Remove escape characters and strip unnecessary whitespaces from a string.\"\"\"\n",
        "    # Remove escape characters like \\n, \\t, \\r, \\\\\n",
        "    s = s.encode('unicode_escape').decode('unicode_escape')\n",
        "    # Remove leading/trailing whitespaces and condense multiple spaces\n",
        "    return re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "def extract_assertions(code: str):\n",
        "    # Updated pattern to support float numbers, complex data types, and various comparisons\n",
        "    pattern = r\"assert\\s+candidate\\((.*?)\\)\\s*==\\s*((\\[.*?\\]|\\(.*?\\)|\\{.*?\\}|'.*?'|\\\".*?\\\"|True|False|None|-?\\d+(?:\\.\\d+)?|\\d+))\"\n",
        "    matches = re.findall(pattern, code, re.DOTALL)\n",
        "\n",
        "    extracted = []\n",
        "    for match in matches:\n",
        "        # arg = clean_string(match[0].strip())  # Clean the argument\n",
        "        arg = match[0]\n",
        "        result = clean_string(match[1].strip())  # Clean the expected result\n",
        "        extracted.append((arg, result))\n",
        "\n",
        "    return extracted"
      ],
      "metadata": {
        "id": "OYXY2omK94HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract_assertions(answer)\n",
        "# extract_assertions(dataset[f'HumanEval/{6}']['test'])"
      ],
      "metadata": {
        "id": "ek5Bd2Uh-XJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args , result = extract_assertions(answer)[1]\n",
        "# print(args)"
      ],
      "metadata": {
        "id": "PhgDfkpxAV2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### testing the evaluation developed"
      ],
      "metadata": {
        "id": "JayeySm0d6eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = 140\n",
        "print(dataset[f'HumanEval/{num}']['prompt']+dataset[f'HumanEval/{num}']['canonical_solution'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx9kROyZ85qU",
        "outputId": "b6543a1f-711b-40e4-80ae-2914d532137a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def fix_spaces(text):\n",
            "    \"\"\"\n",
            "    Given a string text, replace all spaces in it with underscores, \n",
            "    and if a string has more than 2 consecutive spaces, \n",
            "    then replace all consecutive spaces with - \n",
            "    \n",
            "    fix_spaces(\"Example\") == \"Example\"\n",
            "    fix_spaces(\"Example 1\") == \"Example_1\"\n",
            "    fix_spaces(\" Example 2\") == \"_Example_2\"\n",
            "    fix_spaces(\" Example   3\") == \"_Example-3\"\n",
            "    \"\"\"\n",
            "\n",
            "    ans = text\n",
            "    for i in range(len(text), 2, -1):\n",
            "        ans = ans.replace(\" \" * i, \"-\")\n",
            "    return ans.replace(\" \", \"_\")\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[f'HumanEval/{num}']['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMluSUO63JGw",
        "outputId": "13bde18f-a144-4330-c5c1-ff4d96de6b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def check(candidate):\n",
            "\n",
            "    # Check some simple cases\n",
            "    assert candidate(\"Example\") == \"Example\", \"This prints if this assert fails 1 (good for debugging!)\"\n",
            "    assert candidate(\"Mudasir Hanif \") == \"Mudasir_Hanif_\", \"This prints if this assert fails 2 (good for debugging!)\"\n",
            "    assert candidate(\"Yellow Yellow  Dirty  Fellow\") == \"Yellow_Yellow__Dirty__Fellow\", \"This prints if this assert fails 3 (good for debugging!)\"\n",
            "    \n",
            "    # Check some edge cases that are easy to work out by hand.\n",
            "    assert candidate(\"Exa   mple\") == \"Exa-mple\", \"This prints if this assert fails 4 (good for debugging!)\"\n",
            "    assert candidate(\"   Exa 1 2 2 mple\") == \"-Exa_1_2_2_mple\", \"This prints if this assert fails 4 (good for debugging!)\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_assertions(dataset[f'HumanEval/{num}']['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQEHXfXBrkmY",
        "outputId": "73146531-6731-41e3-e533-ec193173fabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"Example\"', '\"Example\"'),\n",
              " ('\"Mudasir Hanif \"', '\"Mudasir_Hanif_\"'),\n",
              " ('\"Yellow Yellow  Dirty  Fellow\"', '\"Yellow_Yellow__Dirty__Fellow\"'),\n",
              " ('\"Exa   mple\"', '\"Exa-mple\"'),\n",
              " ('\"   Exa 1 2 2 mple\"', '\"-Exa_1_2_2_mple\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "valid_code = {True: 0, False: 0}\n",
        "correct_code = {True: 0, False: 0}\n",
        "accuracy_list = []\n",
        "failed_number = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "  print(\"\\n\",i)\n",
        "  answer = dataset[f'HumanEval/{i}']['test']\n",
        "\n",
        "  #check if the answers generated is a valid python code\n",
        "  if is_valid_python(answer):\n",
        "    valid_code[True] += 1\n",
        "  else:\n",
        "    valid_code[False] += 1\n",
        "    print(f\"Invalid code for {i}\")\n",
        "    continue\n",
        "\n",
        "  #Evaluate the answers generated is correct\n",
        "  function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "  assertions = extract_assertions(answer)\n",
        "  accuracy = {\"True\": 0,\"False\": 0}\n",
        "\n",
        "  for arg, predictions in assertions:\n",
        "    code = (f\"{function}\\n\"\n",
        "    f\"result = {dataset[f'HumanEval/{i}']['entry_point']}({arg})\\n\"\n",
        "    f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "    \"print(response, end ='')\")\n",
        "\n",
        "    real_result = run_python_code(code)\n",
        "    if real_result[0] == False:\n",
        "      print(f\"Encountered an error for {arg}\")\n",
        "      accuracy[\"False\"] += 1\n",
        "      continue\n",
        "\n",
        "    real_result = ast.literal_eval(real_result[1])\n",
        "    # print(f\"\\nprediction: {predictions}\")\n",
        "    # print(f\"real result: {real_result}\")\n",
        "    if real_result['type'] == 'str':\n",
        "        # print(predictions)\n",
        "        # print(real_result['result'])\n",
        "        try:\n",
        "            if json.loads(predictions) == real_result['result']:\n",
        "                accuracy[\"True\"] += 1\n",
        "            else:\n",
        "                accuracy[\"False\"] += 1\n",
        "                print(f\"failed for JSON String type args {arg}\")\n",
        "        except:\n",
        "            if predictions == f\"'{real_result['result']}'\":\n",
        "                accuracy[\"True\"] += 1\n",
        "            else:\n",
        "                accuracy[\"False\"] += 1\n",
        "                print(f\"failed for String type args {arg}\")\n",
        "    elif real_result['type'] == 'NoneType':\n",
        "        if predictions == str(real_result['result']):\n",
        "            accuracy[\"True\"] += 1\n",
        "        else:\n",
        "            accuracy[\"False\"] += 1\n",
        "            print(f\"failed for None type args {arg}\")\n",
        "    else:\n",
        "      try:\n",
        "        if eval(real_result['type']+f\"({predictions})\") == eval(real_result['type']+f\"({real_result['result']})\"):\n",
        "          accuracy[\"True\"] += 1\n",
        "      except:\n",
        "        accuracy[\"False\"] += 1\n",
        "\n",
        "\n",
        "  if accuracy[\"True\"] == len(assertions):\n",
        "    correct_code[True] += 1\n",
        "    print(f\"\\nGreat! {i}\")\n",
        "  else:\n",
        "    correct_code[False] += 1\n",
        "    failed_number.append(i)\n",
        "\n",
        "  accuracy_list.append(accuracy)\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d12d3b-1cce-4ad7-a58b-834259ff058a",
        "id": "Iqr59jD_fNlW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 243.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 134\n",
            "\n",
            "Great! 134\n",
            "\n",
            " 135\n",
            "\n",
            "Great! 135\n",
            "\n",
            " 136\n",
            "\n",
            "Great! 136\n",
            "\n",
            " 137\n",
            "\n",
            "Great! 137\n",
            "\n",
            " 138\n",
            "\n",
            "Great! 138\n",
            "\n",
            " 139\n",
            "\n",
            "Great! 139\n",
            "\n",
            " 140\n",
            "\n",
            "Great! 140\n",
            "\n",
            " 141\n",
            "\n",
            "Great! 141\n",
            "\n",
            " 142\n",
            "\n",
            "Great! 142\n",
            "\n",
            " 143\n",
            "\n",
            "Great! 143\n",
            "\n",
            " 144\n",
            "\n",
            "Great! 144\n",
            "\n",
            " 145\n",
            "\n",
            "Great! 145\n",
            "\n",
            " 146\n",
            "\n",
            "Great! 146\n",
            "\n",
            " 147\n",
            "\n",
            "Great! 147\n",
            "\n",
            " 148\n",
            "\n",
            "Great! 148\n",
            "\n",
            " 149\n",
            "\n",
            "Great! 149\n",
            "\n",
            " 150\n",
            "\n",
            "Great! 150\n",
            "\n",
            " 151\n",
            "\n",
            "Great! 151\n",
            "\n",
            " 152\n",
            "\n",
            "Great! 152\n",
            "\n",
            " 153\n",
            "\n",
            "Great! 153\n",
            "\n",
            " 154\n",
            "\n",
            "Great! 154\n",
            "\n",
            " 155\n",
            "\n",
            "Great! 155\n",
            "\n",
            " 156\n",
            "\n",
            "Great! 156\n",
            "\n",
            " 157\n",
            "\n",
            "Great! 157\n",
            "\n",
            " 158\n",
            "\n",
            "Great! 158\n",
            "\n",
            " 159\n",
            "\n",
            "Great! 159\n",
            "\n",
            " 160\n",
            "\n",
            "Great! 160\n",
            "\n",
            " 161\n",
            "\n",
            "Great! 161\n",
            "\n",
            " 162\n",
            "\n",
            "Great! 162\n",
            "\n",
            " 163\n",
            "\n",
            "Great! 163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failed_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTmTY5NapSWO",
        "outputId": "e6df2d1c-0988-4599-85a1-8c8d1fb9f168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(accuracy_list)"
      ],
      "metadata": {
        "id": "syOcv1mOf4XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_code)\n",
        "print(correct_code)\n",
        "\n",
        "print(\"evaluation accuracy: \", correct_code[True]/(correct_code[True]+correct_code[False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ef0f65-a383-41dc-d6b7-89d6f8fc4db9",
        "id": "uuqlTIY3uTLW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{True: 30, False: 0}\n",
            "{True: 30, False: 0}\n",
            "evaluation accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103e2951-e263-4d72-cec2-fbfe258103f1",
        "id": "2QR0VuiguTLZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'True': 10, 'False': 0}, {'True': 5, 'False': 0}, {'True': 11, 'False': 0}, {'True': 8, 'False': 0}, {'True': 8, 'False': 0}, {'True': 4, 'False': 0}, {'True': 5, 'False': 0}, {'True': 26, 'False': 0}, {'True': 11, 'False': 0}, {'True': 7, 'False': 0}, {'True': 13, 'False': 0}, {'True': 6, 'False': 0}, {'True': 7, 'False': 0}, {'True': 4, 'False': 0}, {'True': 7, 'False': 0}, {'True': 7, 'False': 0}, {'True': 10, 'False': 0}, {'True': 6, 'False': 0}, {'True': 4, 'False': 0}, {'True': 9, 'False': 0}, {'True': 6, 'False': 0}, {'True': 8, 'False': 0}, {'True': 14, 'False': 0}, {'True': 11, 'False': 0}, {'True': 0, 'False': 0}, {'True': 6, 'False': 0}, {'True': 3, 'False': 0}, {'True': 8, 'False': 0}, {'True': 4, 'False': 0}, {'True': 4, 'False': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "s4elOzz6DNda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "predicted_data = []\n",
        "valid_code = {True: 0, False: 0}\n",
        "correct_code = {True: 0, False: 0}\n",
        "accuracy_list = []\n",
        "failed_number = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "    data = {}\n",
        "    random_number = random.choice([5, 7, 9,11])\n",
        "\n",
        "    question = f\"\"\"Generate Exactly {random_number} test cases for this function\n",
        "    ```{dataset[f'HumanEval/{i}']['prompt']}```\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = make_llama_3_prompt(question, system)\n",
        "    answer = llm.generate(prompt, max_new_tokens=1000)\n",
        "\n",
        "    data['Number_of_required_test_cases'] = random_number\n",
        "    data['prompt'] = dataset[f'HumanEval/{i}']['prompt']\n",
        "    data['answer'] = answer\n",
        "    predicted_data.append(data)\n",
        "\n",
        "    #check if the answers generated is a valid python code\n",
        "    if is_valid_python(answer):\n",
        "      valid_code[True] += 1\n",
        "    else:\n",
        "      valid_code[False] += 1\n",
        "      print(f\"Invalid code for {i}\")\n",
        "      continue\n",
        "\n",
        "    #Evaluate the answers generated is correct\n",
        "    function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "    assertions = extract_assertions(answer)\n",
        "    accuracy = {\"True\": 0,\"False\": 0}\n",
        "\n",
        "    for arg, predictions in assertions:\n",
        "        code = (f\"{function}\\n\"\n",
        "        f\"result = {dataset[f'HumanEval/{i}']['entry_point']}({arg})\\n\"\n",
        "        f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "        \"print(response, end ='')\")\n",
        "\n",
        "        real_result = run_python_code(code)\n",
        "        if real_result[0] == False:\n",
        "          print(f\"Encountered an error for {arg}\")\n",
        "          accuracy[\"False\"] += 1\n",
        "          continue\n",
        "\n",
        "        real_result = ast.literal_eval(real_result[1])\n",
        "        # print(f\"\\nprediction: {predictions}\")\n",
        "        # print(f\"real result: {real_result}\")\n",
        "        if real_result['type'] == 'str':\n",
        "            # print(predictions)\n",
        "            # print(real_result['result'])\n",
        "            try:\n",
        "                if json.loads(predictions) == real_result['result']:\n",
        "                    accuracy[\"True\"] += 1\n",
        "                else:\n",
        "                    accuracy[\"False\"] += 1\n",
        "                    print(f\"failed for JSON String type args {arg}\")\n",
        "            except:\n",
        "                if predictions == f\"'{real_result['result']}'\":\n",
        "                    accuracy[\"True\"] += 1\n",
        "                else:\n",
        "                    accuracy[\"False\"] += 1\n",
        "                    print(f\"failed for String type args {arg}\")\n",
        "        elif real_result['type'] == 'NoneType':\n",
        "            if predictions == str(real_result['result']):\n",
        "                accuracy[\"True\"] += 1\n",
        "            else:\n",
        "                accuracy[\"False\"] += 1\n",
        "                print(f\"failed for None type args {arg}\")\n",
        "        else:\n",
        "          try:\n",
        "            if eval(real_result['type']+f\"({predictions})\") == eval(real_result['type']+f\"({real_result['result']})\"):\n",
        "              accuracy[\"True\"] += 1\n",
        "          except:\n",
        "            accuracy[\"False\"] += 1\n",
        "\n",
        "\n",
        "    if accuracy[\"True\"] == len(assertions):\n",
        "      correct_code[True] += 1\n",
        "      print(f\"\\nGreat! {i}\")\n",
        "    else:\n",
        "      correct_code[False] += 1\n",
        "      failed_number.append(i)\n",
        "\n",
        "    accuracy_list.append(accuracy)\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f989930c-ac97-42ac-8cbc-45a33f15b260",
        "id": "MeuZFe_ofNlc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 3/30 [00:01<00:16,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [00:02<00:13,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [00:14<02:00,  4.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 7/30 [00:49<05:06, 13.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [01:09<05:42, 15.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 10/30 [01:10<02:34,  7.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [01:11<01:44,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [01:44<04:11, 13.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 19/30 [04:28<05:44, 31.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 20/30 [05:23<06:22, 38.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 22/30 [06:05<03:55, 29.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [06:25<03:06, 26.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 25/30 [07:32<02:31, 30.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy', 'xyxyxyxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy', 'xyxyxyxy', 'xyxyxyxyxy'],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 26/30 [07:33<01:25, 21.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 28/30 [08:06<00:37, 18.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 29/30 [08:40<00:23, 23.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args '12345',\n",
            "failed for String type args 'Hello',\n",
            "failed for String type args '1234567890',\n",
            "failed for String type args 'Hello, World!',\n",
            "failed for String type args '1234567890abcdef',\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [09:34<00:00, 19.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predicted_data[0]['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFnI9iXXH66y",
        "outputId": "93c33cf9-675a-4573-f961-5ae6e409a6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def check(candidate):\n",
            "    assert candidate('apple pie',) == False\n",
            "    assert candidate('apple pi e',) == True\n",
            "    assert candidate('apple pi e ',) == False\n",
            "    assert candidate('',) == False\n",
            "    assert candidate('abc',) == True\n",
            "    assert candidate('123',) == False\n",
            "    assert candidate('abc!',) == True\n",
            "    assert candidate('abc! ',) == False\n",
            "    assert candidate('abc!!',) == True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_code)\n",
        "print(correct_code)\n",
        "\n",
        "print(\"model accuracy: \", correct_code[True]/(correct_code[True]+correct_code[False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691c99e3-01bc-499e-db08-78b6ec2030d3",
        "id": "GauD__bZfNle"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{True: 26, False: 4}\n",
            "{True: 10, False: 16}\n",
            "model accuracy:  0.38461538461538464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5681e797-65dd-4186-a2c3-2ef7a9721ca4",
        "id": "siCTfl02fNle"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'True': 4, 'False': 0}, {'True': 3, 'False': 0}, {'True': 9, 'False': 0}, {'True': 11, 'False': 0}, {'True': 11, 'False': 0}, {'True': 3, 'False': 0}, {'True': 6, 'False': 3}, {'True': 7, 'False': 0}, {'True': 3, 'False': 0}, {'True': 7, 'False': 0}, {'True': 4, 'False': 0}, {'True': 7, 'False': 0}, {'True': 4, 'False': 0}, {'True': 2, 'False': 0}, {'True': 1, 'False': 0}, {'True': 3, 'False': 0}, {'True': 4, 'False': 0}, {'True': 4, 'False': 0}, {'True': 5, 'False': 0}, {'True': 5, 'False': 0}, {'True': 10, 'False': 0}, {'True': 7, 'False': 0}, {'True': 4, 'False': 0}, {'True': 4, 'False': 6}, {'True': 7, 'False': 0}, {'True': 0, 'False': 0}, {'True': 5, 'False': 2}, {'True': 2, 'False': 7}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predicted_data[1]['answer'])"
      ],
      "metadata": {
        "id": "XIqHrhEwfNlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mutation"
      ],
      "metadata": {
        "id": "vbpU2ul4o6-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai -q"
      ],
      "metadata": {
        "id": "SuVuf-ZFGzDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "I93BZ1mXqSAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM = \"\"\"\n",
        "Your role is to mutate the function.\n",
        "Make small controlled changes to the function provided that can lead to chnage in results\n",
        "output only the mutated function\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ta2jnUQRfNli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_model():\n",
        "    genai.configure(api_key=userdata.get('gemini_key'))\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
        "                                  system_instruction=SYSTEM)\n",
        "    return model\n",
        "def program_synthesis(input_prompt: str, model) -> str:\n",
        "    response = model.generate_content(input_prompt,\n",
        "                                      generation_config = genai.GenerationConfig(\n",
        "                                          temperature=0))\n",
        "    response = response.text.replace('```python', '').replace('```', '').strip()\n",
        "    return response\n",
        "\n",
        "model = load_base_model()"
      ],
      "metadata": {
        "id": "1KqPQO91pX-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutation_set = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "  data = {}\n",
        "\n",
        "  prompt = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "  mutation = program_synthesis(prompt, model)\n",
        "\n",
        "  data['function'] = prompt\n",
        "  data['mutation'] = mutation\n",
        "  mutation_set.append(data)"
      ],
      "metadata": {
        "id": "fK7sCerxpX0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc4b0f4c-c2e4-4ec4-d803-dee2976e891b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:57<00:00,  3.90s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File to save the JSON Lines data\n",
        "file_path = \"cs6158_mut_data.jsonl\"\n",
        "\n",
        "# Save the list of dictionaries into a JSONL file\n",
        "with open(file_path, 'w') as jsonl_file:\n",
        "    for record in mutation_set:\n",
        "        jsonl_file.write(json.dumps(record) + '\\n')\n",
        "\n",
        "print(f\"Data saved to {file_path}\")"
      ],
      "metadata": {
        "id": "TXjHa2TffSuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ef4fb9-c3fb-4895-bc84-3f0a9b83ffd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to cs6158_mut_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_code = {True: 0, False: 0}\n",
        "correct_code = {True: 0, False: 0}\n",
        "accuracy_list = []\n",
        "failed_number = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "    data = {}\n",
        "    answer = predicted_data[i-134]['answer']\n",
        "\n",
        "    #check if the answers generated is a valid python code\n",
        "    if is_valid_python(answer):\n",
        "      valid_code[True] += 1\n",
        "    else:\n",
        "      valid_code[False] += 1\n",
        "      print(f\"Invalid code for {i}\")\n",
        "      continue\n",
        "\n",
        "    #Evaluate the answers generated is correct\n",
        "    function = mutation_set[i-134]['mutation']\n",
        "    assertions = extract_assertions(answer)\n",
        "    accuracy = {\"True\": 0,\"False\": 0}\n",
        "\n",
        "    for arg, predictions in assertions:\n",
        "        code = (f\"{function}\\n\"\n",
        "        f\"result = {dataset[f'HumanEval/{i}']['entry_point']}({arg})\\n\"\n",
        "        f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "        \"print(response, end ='')\")\n",
        "\n",
        "        real_result = run_python_code(code)\n",
        "        if real_result[0] == False:\n",
        "          print(f\"Encountered an error for {arg}\")\n",
        "          accuracy[\"False\"] += 1\n",
        "          continue\n",
        "\n",
        "        real_result = ast.literal_eval(real_result[1])\n",
        "        # print(f\"\\nprediction: {predictions}\")\n",
        "        # print(f\"real result: {real_result}\")\n",
        "        if real_result['type'] == 'str':\n",
        "            # print(predictions)\n",
        "            # print(real_result['result'])\n",
        "            try:\n",
        "                if json.loads(predictions) == real_result['result']:\n",
        "                    accuracy[\"True\"] += 1\n",
        "                else:\n",
        "                    accuracy[\"False\"] += 1\n",
        "                    print(f\"failed for JSON String type args {arg}\")\n",
        "            except:\n",
        "                if predictions == f\"'{real_result['result']}'\":\n",
        "                    accuracy[\"True\"] += 1\n",
        "                else:\n",
        "                    accuracy[\"False\"] += 1\n",
        "                    print(f\"failed for String type args {arg}\")\n",
        "        elif real_result['type'] == 'NoneType':\n",
        "            if predictions == str(real_result['result']):\n",
        "                accuracy[\"True\"] += 1\n",
        "            else:\n",
        "                accuracy[\"False\"] += 1\n",
        "                print(f\"failed for None type args {arg}\")\n",
        "        else:\n",
        "          try:\n",
        "            if eval(real_result['type']+f\"({predictions})\") == eval(real_result['type']+f\"({real_result['result']})\"):\n",
        "              accuracy[\"True\"] += 1\n",
        "          except:\n",
        "            accuracy[\"False\"] += 1\n",
        "\n",
        "\n",
        "    if accuracy[\"True\"] == len(assertions):\n",
        "      correct_code[True] += 1\n",
        "      print(f\"\\nGreat! {i}\")\n",
        "    else:\n",
        "      correct_code[False] += 1\n",
        "      failed_number.append(i)\n",
        "\n",
        "    accuracy_list.append(accuracy)\n",
        "    # break"
      ],
      "metadata": {
        "id": "jOgVBKM-fSpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87523cb-c09a-4b20-9b69-d6467a04c187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 339.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 137\n",
            "failed for String type args 'Hello  World!',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "failed for String type args 'Hello  World !',\n",
            "\n",
            "Great! 141\n",
            "\n",
            "Great! 143\n",
            "\n",
            "Great! 145\n",
            "Invalid code for 152\n",
            "Invalid code for 153\n",
            "\n",
            "Great! 155\n",
            "\n",
            "Great! 156\n",
            "failed for String type args ['x', 'y', 'z'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy', 'xyxyxyxy'],\n",
            "failed for String type args ['x', 'y', 'xy', 'xxy', 'xyxy', 'xyxyxy', 'xyxyxyxy', 'xyxyxyxyxy'],\n",
            "\n",
            "Great! 159\n",
            "Encountered an error for ['+', '*'], [2, 3]\n",
            "Encountered an error for ['+', '*'], [2, 3, 4]\n",
            "Encountered an error for ['+', '*'], [2, 3, 4, 5]\n",
            "Encountered an error for ['+', '*'], [2, 3, 4, 5, 6]\n",
            "Encountered an error for ['+', '*'], [2, 3, 4, 5, 6, 7]\n",
            "\n",
            "Great! 161\n",
            "failed for String type args '',\n",
            "failed for String type args '12345',\n",
            "failed for String type args 'Hello',\n",
            "failed for String type args '1234567890',\n",
            "failed for String type args 'Hello, World!',\n",
            "failed for String type args '1234567890abcdef',\n",
            "Invalid code for 163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_code)\n",
        "print(correct_code)\n",
        "\n",
        "print(\"model accuracy: \", correct_code[True]/(correct_code[True]+correct_code[False]))"
      ],
      "metadata": {
        "id": "6c9KaZIIfSjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f192b33d-5376-4b0c-be7c-30f57d7270f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{True: 26, False: 4}\n",
            "{True: 7, False: 19}\n",
            "model accuracy:  0.2692307692307692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Other LLMs"
      ],
      "metadata": {
        "id": "UO9lM0VKSaa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_sys = \"\"\"\n",
        "You are a powerful docstring_text-to-unit_test model.\n",
        "Your job is to generate unit tests from docstring.\"\n",
        "You will be given a docstring detailing what the function does\n",
        "\n",
        "use this as examples\n",
        "\n",
        "input: Generate 5 test cases for this function\n",
        "def remove_vowels(text):\n",
        "    '''\n",
        "    remove_vowels is a function that takes string and returns string without vowels.\n",
        "    >>> remove_vowels('')\n",
        "    ''\n",
        "    >>> remove_vowels(\"abcdef\\nghijklm\")\n",
        "    'bcdf\\nghjklm'\n",
        "    >>> remove_vowels('abcdef')\n",
        "    'bcdf'\n",
        "    >>> remove_vowels('aaaaa')\n",
        "    ''\n",
        "    >>> remove_vowels('aaBAA')\n",
        "    'B'\n",
        "    >>> remove_vowels('zbcd')\n",
        "    'zbcd'\n",
        "    '''\n",
        "output:\n",
        "def check(candidate):\n",
        "    assert candidate('') == ''\n",
        "    assert candidate(\"abcdef\\nghijklm\") == 'bcdf\\nghjklm'\n",
        "    assert candidate('fedcba') == 'fdcb'\n",
        "    assert candidate('eeeee') == ''\n",
        "    assert candidate('acBAA') == 'cB'\n",
        "\n",
        "Another example\n",
        "\n",
        "input: generate 7 test cases for this function\n",
        "def is_simple_power(x, n):\n",
        "    '''Your task is to write a function that returns true if a number x is a simple\n",
        "    power of n and false in other cases.\n",
        "    x is a simple power of n if n**int=x\n",
        "    For example:\n",
        "    is_simple_power(1, 4) => true\n",
        "    is_simple_power(2, 2) => true\n",
        "    is_simple_power(8, 2) => true\n",
        "    is_simple_power(3, 2) => false\n",
        "    is_simple_power(3, 1) => false\n",
        "    is_simple_power(5, 3) => false\n",
        "    '''\n",
        "output:\n",
        "def check(candidate):\n",
        "    assert candidate(16, 2)== True\n",
        "    assert candidate(143214, 16)== False\n",
        "    assert candidate(4, 2)==True\n",
        "    assert candidate(9, 3)==True\n",
        "    assert candidate(16, 4)==True\n",
        "    assert candidate(24, 2)==False\n",
        "    assert candidate(128, 4)==False\n",
        "\n",
        "\n",
        "note: you only output the test function only as seen in the examples above\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WaaOVIewRWFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### gemini"
      ],
      "metadata": {
        "id": "TsG-nNIUGMFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_model():\n",
        "    genai.configure(api_key=userdata.get('gemini_key'))\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
        "                                  system_instruction=gen_sys)\n",
        "    return model\n",
        "def program_synthesis(input_prompt: str, model) -> str:\n",
        "    response = model.generate_content(input_prompt,\n",
        "                                      generation_config = genai.GenerationConfig(\n",
        "                                          temperature=0))\n",
        "    response = response.text.replace('```python', '').replace('```', '').strip()\n",
        "    return response\n",
        "\n",
        "\n",
        "model = load_base_model()"
      ],
      "metadata": {
        "id": "9rasOGApDZ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "gemini_predictions = []\n",
        "valid_code = {True: 0, False: 0}\n",
        "correct_code = {True: 0, False: 0}\n",
        "accuracy_list = []\n",
        "failed_number = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "  data = {}\n",
        "  random_number = random.choice([5, 7, 9,11])\n",
        "\n",
        "  question = f\"\"\"Generate Exactly {random_number} test cases for this function\n",
        "  ```{dataset[f'HumanEval/{i}']['prompt']}```\n",
        "  \"\"\"\n",
        "  gen_answer = program_synthesis(question, model)\n",
        "\n",
        "  data['Number_of_required_test_cases'] = random_number\n",
        "  data['prompt'] = prompt\n",
        "  data['mutation'] = gen_answer\n",
        "  gemini_predictions.append(data)\n",
        "\n",
        "  #check if the answers generated is a valid python code\n",
        "  if is_valid_python(gen_answer):\n",
        "    valid_code[True] += 1\n",
        "  else:\n",
        "    valid_code[False] += 1\n",
        "    print(f\"Invalid code for {i}\")\n",
        "    continue\n",
        "\n",
        "  #Evaluate the answers generated is correct\n",
        "  function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "  assertions = extract_assertions(gen_answer)\n",
        "  accuracy = {\"True\": 0,\"False\": 0}\n",
        "\n",
        "  for arg, predictions in assertions:\n",
        "      code = (f\"{function}\\n\"\n",
        "      f\"result = {dataset[f'HumanEval/{i}']['entry_point']}({arg})\\n\"\n",
        "      f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "      \"print(response, end ='')\")\n",
        "\n",
        "      real_result = run_python_code(code)\n",
        "      if real_result[0] == False:\n",
        "        print(f\"Encountered an error for {arg}\")\n",
        "        accuracy[\"False\"] += 1\n",
        "        continue\n",
        "\n",
        "      real_result = ast.literal_eval(real_result[1])\n",
        "      # print(f\"\\nprediction: {predictions}\")\n",
        "      # print(f\"real result: {real_result}\")\n",
        "      if real_result['type'] == 'str':\n",
        "          # print(predictions)\n",
        "          # print(real_result['result'])\n",
        "          try:\n",
        "              if json.loads(predictions) == real_result['result']:\n",
        "                  accuracy[\"True\"] += 1\n",
        "              else:\n",
        "                  accuracy[\"False\"] += 1\n",
        "                  print(f\"failed for JSON String type args {arg}\")\n",
        "          except:\n",
        "              if predictions == f\"'{real_result['result']}'\":\n",
        "                  accuracy[\"True\"] += 1\n",
        "              else:\n",
        "                  accuracy[\"False\"] += 1\n",
        "                  print(f\"failed for String type args {arg}\")\n",
        "      elif real_result['type'] == 'NoneType':\n",
        "          if predictions == str(real_result['result']):\n",
        "              accuracy[\"True\"] += 1\n",
        "          else:\n",
        "              accuracy[\"False\"] += 1\n",
        "              print(f\"failed for None type args {arg}\")\n",
        "      else:\n",
        "        try:\n",
        "          if eval(real_result['type']+f\"({predictions})\") == eval(real_result['type']+f\"({real_result['result']})\"):\n",
        "            accuracy[\"True\"] += 1\n",
        "        except:\n",
        "          accuracy[\"False\"] += 1\n",
        "\n",
        "\n",
        "  if accuracy[\"True\"] == len(assertions):\n",
        "    correct_code[True] += 1\n",
        "    print(f\"\\nGreat! {i}\")\n",
        "  else:\n",
        "    correct_code[False] += 1\n",
        "    failed_number.append(i)\n",
        "\n",
        "  accuracy_list.append(accuracy)\n",
        "  time.sleep(1)\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "OBxo4vxiCaeS",
        "outputId": "767abfb1-86cb-4f8d-ee49-979813adb2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2/30 [00:09<02:24,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:13<02:01,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for None type args \"10\", \"10.0\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 5/30 [00:20<01:32,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [00:23<01:21,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"  a  b   c    d     e\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [00:26<01:15,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 9/30 [00:34<01:19,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"This is a simple test case\"\n",
            "failed for JSON String type args \"one two three four five six seven eight nine ten\"\n",
            "failed for JSON String type args \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
            "failed for JSON String type args \"aa\"\n",
            "failed for JSON String type args \"aaa\"\n",
            "failed for JSON String type args \"aaaaa\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [00:38<01:14,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 12/30 [00:45<01:09,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 14/30 [00:53<00:58,  3.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 16/30 [00:59<00:49,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 17/30 [01:02<00:44,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 18/30 [01:05<00:38,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [01:09<00:36,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 20/30 [01:13<00:37,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 22/30 [01:20<00:28,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [01:23<00:24,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 24/30 [01:27<00:20,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args [\"apple\", \"banana\", \"kiwi\"]\n",
            "failed for JSON String type args [\"hello\", \"world\", \"python\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 25/30 [01:30<00:17,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 27/30 [01:38<00:11,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"1A2B3C4D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [01:42<00:07,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid Python code\n",
            "Encountered an error for '') is None\n",
            "    assert candidate('test'\n",
            "failed for String type args 'This is a longer string'\n",
            "failed for String type args 'Another string'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:50<00:00,  3.68s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_code)\n",
        "print(correct_code)\n",
        "\n",
        "print(\"model accuracy: \", correct_code[True]/(correct_code[True]+correct_code[False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKNKcnTbDowx",
        "outputId": "dc81592d-4dd9-478d-9255-97abbbc63075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{True: 30, False: 0}\n",
            "{True: 14, False: 16}\n",
            "model accuracy:  0.4666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### gpt"
      ],
      "metadata": {
        "id": "uRc0BXpyGPv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "id": "5MVbzw1NFSSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4146a02f-75c6-471a-ef57-60ff4c930bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "2z73b0Eyl9Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import time\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_key')\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "uIJp8sNgk6dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def openai_program_synthesis(input_prompt: str) -> str:\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\", #gpt-3.5-turbo\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": gen_sys},\n",
        "      {\"role\": \"user\", \"content\": input_prompt}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "YMZ4723iG8dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_predictions = []\n",
        "valid_code = {True: 0, False: 0}\n",
        "correct_code = {True: 0, False: 0}\n",
        "accuracy_list = []\n",
        "failed_number = []\n",
        "\n",
        "for i in tqdm(range(134,164)):\n",
        "  data = {}\n",
        "  random_number = random.choice([5, 7, 9,11])\n",
        "\n",
        "  question = f\"\"\"Generate Exactly {random_number} test cases for this function only in the correct format and be professional, give the answer only\n",
        "  ```{dataset[f'HumanEval/{i}']['prompt']}```\n",
        "  \"\"\"\n",
        "  gen_answer = openai_program_synthesis(question)\n",
        "  # print(gen_answer)\n",
        "\n",
        "  data['Number_of_required_test_cases'] = random_number\n",
        "  data['prompt'] = question\n",
        "  data['answer'] = gen_answer\n",
        "  openai_predictions.append(data)\n",
        "\n",
        "  #check if the answers generated is a valid python code\n",
        "  if is_valid_python(gen_answer):\n",
        "    valid_code[True] += 1\n",
        "  else:\n",
        "    valid_code[False] += 1\n",
        "    print(f\"Invalid code for {i}\")\n",
        "    continue\n",
        "\n",
        "  #Evaluate the answers generated is correct\n",
        "  function = dataset[f'HumanEval/{i}']['prompt'] + dataset[f'HumanEval/{i}']['canonical_solution']\n",
        "  assertions = extract_assertions(gen_answer)\n",
        "  accuracy = {\"True\": 0,\"False\": 0}\n",
        "\n",
        "  for arg, predictions in assertions:\n",
        "      code = (f\"{function}\\n\"\n",
        "      f\"result = {dataset[f'HumanEval/{i}']['entry_point']}({arg})\\n\"\n",
        "      f\"response = {{'result': result,'type': type(result).__name__}}\\n\"\n",
        "      \"print(response, end ='')\")\n",
        "\n",
        "      real_result = run_python_code(code)\n",
        "      if real_result[0] == False:\n",
        "        print(f\"Encountered an error for {arg}\")\n",
        "        accuracy[\"False\"] += 1\n",
        "        continue\n",
        "\n",
        "      real_result = ast.literal_eval(real_result[1])\n",
        "      # print(f\"\\nprediction: {predictions}\")\n",
        "      # print(f\"real result: {real_result}\")\n",
        "      if real_result['type'] == 'str':\n",
        "          # print(predictions)\n",
        "          # print(real_result['result'])\n",
        "          try:\n",
        "              if json.loads(predictions) == real_result['result']:\n",
        "                  accuracy[\"True\"] += 1\n",
        "              else:\n",
        "                  accuracy[\"False\"] += 1\n",
        "                  print(f\"failed for JSON String type args {arg}\")\n",
        "          except:\n",
        "              if predictions == f\"'{real_result['result']}'\":\n",
        "                  accuracy[\"True\"] += 1\n",
        "              else:\n",
        "                  accuracy[\"False\"] += 1\n",
        "                  print(f\"failed for String type args {arg}\")\n",
        "      elif real_result['type'] == 'NoneType':\n",
        "          if predictions == str(real_result['result']):\n",
        "              accuracy[\"True\"] += 1\n",
        "          else:\n",
        "              accuracy[\"False\"] += 1\n",
        "              print(f\"failed for None type args {arg}\")\n",
        "      else:\n",
        "        try:\n",
        "          if eval(real_result['type']+f\"({predictions})\") == eval(real_result['type']+f\"({real_result['result']})\"):\n",
        "            accuracy[\"True\"] += 1\n",
        "        except:\n",
        "          accuracy[\"False\"] += 1\n",
        "\n",
        "\n",
        "  if accuracy[\"True\"] == len(assertions):\n",
        "    correct_code[True] += 1\n",
        "    print(f\"\\nGreat! {i}\")\n",
        "  else:\n",
        "    correct_code[False] += 1\n",
        "    failed_number.append(i)\n",
        "\n",
        "  accuracy_list.append(accuracy)\n",
        "  time.sleep(1)\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhVUnc_oHOGO",
        "outputId": "0c75f0cf-515b-4667-f473-960a4b722036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2/30 [00:05<01:17,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:07<01:09,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"-3,5\", \"-3.6\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [00:10<01:06,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [00:12<00:58,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [00:14<00:54,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"  \"\n",
            "failed for JSON String type args \"A  B  C\"\n",
            "failed for JSON String type args \"  D      E\"\n",
            "failed for JSON String type args \"F   G HI  \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [00:16<00:54,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args \"file1.txt\"\n",
            "failed for String type args \"file.txt\"\n",
            "failed for String type args \"fil.exe\"\n",
            "failed for String type args \"file21.exe\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [00:19<00:52,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [00:22<00:55,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"coding is fun\"\n",
            "failed for JSON String type args \"a quick brown fox jumps\"\n",
            "failed for JSON String type args \"we are learning programming\"\n",
            "failed for JSON String type args \"math is interesting\"\n",
            "failed for JSON String type args \"checking the prime words\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [00:24<00:49,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [00:27<00:48,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 13/30 [00:33<00:43,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid code for 146\n",
            "\n",
            "Great! 147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 15/30 [00:37<00:35,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [00:41<00:39,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 18/30 [00:45<00:30,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [00:49<00:32,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args 'MyClass', ['strongOne', 'WeakOne', 'MediumOne']\n",
            "failed for String type args 'TestStreng', ['Test', 'StRongT', 'Sad']\n",
            "failed for String type args 'MyNewClass', ['EXample', 'SaMpLe', 'StreNgth']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 22/30 [00:58<00:23,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [01:01<00:19,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Great! 157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 24/30 [01:03<00:16,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args [\"apple\", \"banana\", \"cat\"]\n",
            "failed for JSON String type args [\"a\", \"bb\", \"ccc\", \"dddd\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 27/30 [01:11<00:08,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for JSON String type args \"123#\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [01:14<00:05,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed for String type args 'MD5 hash'\n",
            "failed for String type args 'Testing MD5'\n",
            "failed for String type args 'python'\n",
            "failed for String type args 'md5'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:21<00:00,  2.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_code)\n",
        "print(correct_code)\n",
        "\n",
        "print(\"model accuracy: \", correct_code[True]/(correct_code[True]+correct_code[False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPdw254gISRd",
        "outputId": "7bb72dda-95be-4dfb-e61d-23675b20e787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{True: 29, False: 1}\n",
            "{True: 12, False: 17}\n",
            "model accuracy:  0.41379310344827586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4wQFYsSI3aH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gr7B8ptRPfXJ",
        "T6yAtSBXZNUO",
        "oSXap797Pn6S",
        "lbcNEzFWxC3L",
        "HvlB08CN33cc",
        "H3LM-eb_xH6S",
        "bRi0NMtj490F",
        "eRs7UqwKuzoj",
        "UzmW1PcfxpdF",
        "y1A22yqX6H2t",
        "JayeySm0d6eJ",
        "s4elOzz6DNda",
        "vbpU2ul4o6-c",
        "TsG-nNIUGMFK"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}